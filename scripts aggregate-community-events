#!/usr/bin/env python3
"""
Aggregate approved community event submissions from GitHub Issues into JSON feeds.

Outputs:
- community-events.json (combined feed at repo root)
- feeds/<state-slug>.json (per-state feeds)

Only processes issues with labels: community + approved
"""

import json
import os
import re
import sys
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List

try:
    import requests
except ImportError:
    print("ERROR: 'requests' library not found. Install with: pip install requests")
    sys.exit(1)

GITHUB_TOKEN = os.environ.get("GITHUB_TOKEN")
REPO = os.environ.get("REPO", "owner/repo")
API_BASE = f"https://api.github.com/repos/{REPO}"

# Check for required environment variables
if not GITHUB_TOKEN:
    print("ERROR: GITHUB_TOKEN environment variable not set")
    sys.exit(1)

if REPO == "owner/repo":
    print("ERROR: REPO environment variable not set")
    sys.exit(1)

HEADERS = {
    "Authorization": f"token {GITHUB_TOKEN}",
    "Accept": "application/vnd.github.v3+json",
}

print(f"ğŸ”§ Configuration:")
print(f"   Repository: {REPO}")
print(f"   API Base: {API_BASE}")
print(f"   Token: {'âœ“ Set' if GITHUB_TOKEN else 'âœ— Missing'}")
print()


def slugify(text: str) -> str:
    """Convert state name to lowercase slug (e.g., 'Ohio' -> 'ohio')."""
    return re.sub(r"[^a-z0-9]+", "-", text.lower()).strip("-")


def parse_issue_body(body: str) -> Dict[str, Any]:
    """
    Parse GitHub issue body from the Community Event Submission template.
    Expected format:
    
    ### Event Title
    <title>
    
    ### Event Date
    <date>
    
    ### State
    <state>
    
    ### County
    <county>
    
    ### Event Type
    <type>
    
    ### Additional Notes
    <notes>
    """
    result = {
        "title": "",
        "date": "",
        "state": "",
        "county": "",
        "type": "other",
        "notes": "",
    }
    
    if not body:
        return result
    
    # Split by ### headers
    sections = re.split(r"###\s+", body)
    
    for section in sections:
        section = section.strip()
        if not section:
            continue
            
        lines = section.split("\n", 1)
        header = lines[0].strip().lower()
        content = lines[1].strip() if len(lines) > 1 else ""
        
        # Remove common markdown artifacts
        content = re.sub(r"^[_*]+|[_*]+$", "", content).strip()
        content = re.sub(r"^-\s+", "", content).strip()
        # Remove "No response" placeholder
        if content.lower() in ["no response", "_no response_"]:
            content = ""
        
        if "event title" in header or header == "title":
            result["title"] = content
        elif "event date" in header or header == "date":
            result["date"] = content
        elif "state" in header:
            result["state"] = content
        elif "county" in header:
            result["county"] = content
        elif "event type" in header or "type" in header:
            result["type"] = content.lower()
        elif "note" in header or "additional" in header:
            result["notes"] = content
    
    return result


def normalize_event_type(raw_type: str) -> str:
    """Normalize event type to: hunting, fishing, or other."""
    raw_lower = raw_type.lower().strip()
    
    if any(word in raw_lower for word in ["hunt", "deer", "turkey", "waterfowl", "upland"]):
        return "hunting"
    elif any(word in raw_lower for word in ["fish", "stock", "trout", "bass"]):
        return "fishing"
    else:
        return "other"


def normalize_date(date_str: str) -> str:
    """
    Convert various date formats to ISO8601 with Zulu timezone.
    Accepts: ISO8601, YYYY-MM-DD, MM/DD/YYYY, etc.
    Returns: YYYY-MM-DDTHH:MM:SSZ
    """
    date_str = date_str.strip()
    
    # Try parsing various formats
    formats = [
        "%Y-%m-%dT%H:%M:%SZ",
        "%Y-%m-%dT%H:%M:%S",
        "%Y-%m-%d",
        "%m/%d/%Y",
        "%m-%d-%Y",
        "%d/%m/%Y",
    ]
    
    for fmt in formats:
        try:
            dt = datetime.strptime(date_str, fmt)
            # Default to 23:59:00 UTC if no time specified
            if "T" not in date_str:
                dt = dt.replace(hour=23, minute=59, second=0)
            return dt.strftime("%Y-%m-%dT%H:%M:%SZ")
        except ValueError:
            continue
    
    # If all parsing fails, return as-is (validation will catch it)
    return date_str


def fetch_approved_issues() -> List[Dict]:
    """Fetch all open issues with 'community' and 'approved' labels."""
    url = f"{API_BASE}/issues"
    params = {
        "state": "open",
        "labels": "community,approved",
        "per_page": 100,
    }
    
    issues = []
    page = 1
    
    try:
        while True:
            params["page"] = page
            print(f"   Fetching page {page}...")
            response = requests.get(url, headers=HEADERS, params=params, timeout=30)
            
            if response.status_code == 401:
                print("ERROR: Authentication failed. Check GITHUB_TOKEN.")
                sys.exit(1)
            elif response.status_code == 404:
                print(f"ERROR: Repository not found: {REPO}")
                sys.exit(1)
            
            response.raise_for_status()
            
            batch = response.json()
            if not batch:
                break
                
            issues.extend(batch)
            page += 1
            
            # Safety limit
            if page > 10:
                print("WARNING: Reached page limit (10). Some issues may be missed.")
                break
    
    except requests.exceptions.RequestException as e:
        print(f"ERROR: Failed to fetch issues: {e}")
        sys.exit(1)
    
    return issues


def validate_event(event: Dict) -> bool:
    """Check if event has all required fields."""
    required = ["title", "date", "state", "county", "type"]
    
    for field in required:
        if not event.get(field):
            return False
    
    # Validate date format
    date_str = event["date"]
    try:
        datetime.strptime(date_str, "%Y-%m-%dT%H:%M:%SZ")
    except ValueError:
        return False
    
    return True


def main():
    print(f"ğŸ” Fetching approved community events from {REPO}...")
    print()
    
    issues = fetch_approved_issues()
    print(f"âœ“ Found {len(issues)} approved issue(s).")
    print()
    
    if len(issues) == 0:
        print("âš ï¸  No approved issues found. Creating empty feeds...")
        events = []
        per_state = {}
    else:
        events = []
        per_state = {}
        
        for issue in issues:
            issue_num = issue.get("number", "?")
            body = issue.get("body", "")
            
            print(f"ğŸ“‹ Processing issue #{issue_num}...")
            
            parsed = parse_issue_body(body)
            
            # Normalize
            parsed["type"] = normalize_event_type(parsed["type"])
            parsed["date"] = normalize_date(parsed["date"])
            
            # Validate
            if not validate_event(parsed):
                print(f"   âš ï¸  Skipping: Invalid or missing required fields")
                print(f"      Title: {parsed['title'][:50] if parsed['title'] else '(empty)'}")
                print(f"      Date: {parsed['date'] if parsed['date'] else '(empty)'}")
                print(f"      State: {parsed['state'] if parsed['state'] else '(empty)'}")
                print(f"      County: {parsed['county'] if parsed['county'] else '(empty)'}")
                print()
                continue
            
            # Build event object
            event = {
                "title": parsed["title"],
                "date": parsed["date"],
                "state": parsed["state"],
                "county": parsed["county"],
                "type": parsed["type"],
                "notes": parsed["notes"],
            }
            
            events.append(event)
            
            # Group by state
            state_slug = slugify(parsed["state"])
            if state_slug not in per_state:
                per_state[state_slug] = []
            per_state[state_slug].append(event)
            
            print(f"   âœ“ Imported: {parsed['title']} ({parsed['state']}, {parsed['county']})")
            print()
    
    # Write combined feed
    print("ğŸ“ Writing feeds...")
    try:
        combined_path = Path("community-events.json")
        combined_path.write_text(json.dumps(events, indent=2, ensure_ascii=False))
        print(f"   âœ“ Wrote {len(events)} event(s) to {combined_path}")
    except Exception as e:
        print(f"   ERROR: Failed to write combined feed: {e}")
        sys.exit(1)
    
    # Write per-state feeds
    try:
        feeds_dir = Path("feeds")
        feeds_dir.mkdir(exist_ok=True)
        
        if per_state:
            for state_slug, state_events in per_state.items():
                state_path = feeds_dir / f"{state_slug}.json"
                state_path.write_text(json.dumps(state_events, indent=2, ensure_ascii=False))
                print(f"   âœ“ Wrote {len(state_events)} event(s) to {state_path}")
        else:
            print(f"   â„¹ï¸  No per-state feeds to write (no events)")
    except Exception as e:
        print(f"   ERROR: Failed to write per-state feeds: {e}")
        sys.exit(1)
    
    print()
    print("âœ… Community events aggregation complete!")
    print(f"   Total events: {len(events)}")
    print(f"   States: {len(per_state)}")


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nâš ï¸  Interrupted by user")
        sys.exit(1)
    except Exception as e:
        print(f"\n\nâŒ FATAL ERROR: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
